
## Introduction

The intent clarify component is to understand the question, and guide the retrieval to obtain better documents. Usually, there could be different types of understanding, e.g., whether to retrieve and query formulations.



## 1. Retrieval Detection <a id="retrieval_detect"></a>

These kind of methods try to determine whether to retrieve content for response generation or directly generate the response.

| Date       | Title | Authors   | Orgnization | Abs    | Dataset  | 
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/05/04| [When to Retrieve: Teaching LLMs to Utilize Information Retrieval Effectively](https://arxiv.org/pdf/2404.19705) <br>[[code](https://github.com/mwozgpt/Adapt-LLM-anonymous-old): ![](https://img.shields.io/github/stars/mwozgpt/Adapt-LLM-anonymous-old.svg?style=social)] | Tiziano Labruna, et al. | University of Bozen-Bolzano | <details><summary><small>This paper presents ADAPT-LLM ...</small></summary><small>This paper presents ADAPT-LLM by fine-tuning a base LLM on an open-domain QA dataset. It first take base LLM to zero-shot evaluation to determin its accuracy in QA. For questions with incorrect answers, it train the LLM to generate a spectial token <RET>, indicating the need for additional context.</small></details>|<sub>NQ, SQuAD, PopQA</sub>|
|2023/10/08| [Self-Knowledge Guided Retrieval Augmentation for Large Language Models](https://arxiv.org/pdf/2310.05002.pdf) |Yile Wang, Peng Li, Maosong Sun, Yang Liu|Tsinghua University| <details><summary><small>This paper presents SKR ...</small></summary><small>This work introduces Self-Knowledge guided Retrieval augmentation*SKR* to flexibly call the retriever. Three steps: 1) collection self-knowledge of LLM by asking a number of questions, and divide the question into two categories D+ and D- according to the answer correctness, 2) eliciting self-knowledge of LLMs by either direct prompt or training a classifier based on D+ and D-, 3) using self-knowledge for adaptive retrieval augmentation based on prediction of 2).</small></details>| <sub>TemporalQA, CommonsenseQA, TabularQA, StrategyQA, TruthfulQA</sub> |

## 2. Query Reformulation <a id="query_reformulate"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset|
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| 2024/03/31 | [RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation](https://arxiv.org/pdf/2404.00610.pdf)| Chi-Min Chan, Chunpu Xu, Ruibin Yuan, et. al. |Hong Kong University of Science and Technology, Hong Kong Polytechnic University, MIT|<details><summary><small>This paper presents RQ-RAG ...</small></summary><small>This work proposes RQ-RAG (Refine Query RAG) to enhance the generator (LLaMA2) to explicitly rewrite, decompose, and disambiguate, before final answer generation. In this way, the RAG process interleaves between retrieval (guided by refined query) and generation.  </small></details> | <sub>Arc-Challenge, PopQA, OpenbookQA, HotpotQA, 2WikiMHQA, Musique</sub> |

## 3. Query Expansion <a id="retrieval_expansion"></a>

### 3.1 Generative-Relevance Feedback <a id="GRF"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| 2025/09/09 | [Query Expansion in the Age of Pre-trained and Large Language Models: A Comprehensive Survey](https://arxiv.org/pdf/2509.07794) | MingHan Li, XinXuan Lv, JunJie Zou, et al. |Soochow University, China|<details><summary><small>This paper presents survey of QE ...</small></summary><small>This paper introduce a four-dimensional framework for QE: 1) the point of injection (explicit vs. implicit QE), 2) grounding and interaction (knowledge bases, model-internal capabilities, multi-turn retrieval), 3) learning alignment, 4)knowledge graph-based argumentation.</small></details> | <sub>...</sub> |
| 2025/06/16 | [TongSearch-QR: Reinforced Query Reasoning for Retrieval](https://arxiv.org/pdf/2506.11603)<br>[[code](https://github.com/bigai-nlco/TongSearch-QR): ![](https://img.shields.io/github/stars/bigai-nlco/TongSearch-QR.svg?style=social)] | Xubo Qin, Jun Bai, Jiaqi Li, Zixia Jia, Zilong Zheng |BIGAI|<details><summary><small>This paper presents **TongSearch-QE** ...</small></summary><small>The **TongSearch-QE** developed a rule-based reward function for GRPO, enabling RL on the query reasoning of smaller language models.</small></details> | <sub>BRIGHT</sub> |
| 2025/06/10 | [ThinkQE: Query Expansion via an Evolving Thinking Process](https://arxiv.org/pdf/2506.09260)<br>[[code](https://github.com/Yibin-Lei/Think_QE): ![](https://img.shields.io/github/stars/Yibin-Lei/Think_QE.svg?style=social)] | Yibin Lei, Tao Shen, Andrew Yates|University of Amsterdam|<details><summary><small>This paper presents **ThinkQE** ...</small></summary><small>The **ThinkQE** consists of two key components: a thinking-based expansion process that encourages deeper and comprehensive semantic exploration, and a corpus-interaction strategy that iteratively refines expansions using retrieval feedback from the corpus.</small></details> | <sub>TREC DL19 and DL20, BRIGHT</sub> |
| 2024/11/12 | [Exploring the Best Practices of Query Expansion with Large Language Models](https://aclanthology.org/2024.findings-emnlp.103.pdf)<br>[[code](https://github.com/lezhang7/Retrieval_MuGI): ![](https://img.shields.io/github/stars/lezhang7/Retrieval_MuGI.svg?style=social)] | Le Zhang, Yihong Wu, Qian Yang, et. al. |University of Montreal|<details><summary><small>This paper presents **MUGI** ...</small></summary><small>This work proposes MUGI (Multi-Text Generation Integration), which leverages LLM to generate multiple pseudo-references. Findings: 1) increasing the number of references from LLM benefits IR systems; 2) A balance between the query and pseudo-documents, and an effective integration strategy is important; 3) contextual information from LLM is essential.  </small></details> | <sub>TREC DL19 and DL20, BEIR</sub> |
| 2024/10/21 | [GaQR: An Efficient Generation-augmented Question Rewriter](https://dl.acm.org/doi/10.1145/3627673.3679930) | Oliver Young, Yixing Fan, Ruqing Zhang, et al.|  ICT, CAS | <details><summary><small>This paper presents GaQR ...</small></summary><small>The work proposes introduce an efficient GaQR to reformulate a question into several queries using Chain of Thought (CoT) and make it more efficient through knowledge distillation.</small></details> | <sub> MS MARCO, Miracl, BEIR</sub> |
| 2024/09/17 | [MGenCRF: Generative Clustering and Reformulation Framework for Enhanced Intent-Driven Information Retrieval](https://arxiv.org/pdf/2409.10909) | Wonduk Seo, Haojie Zhang, Yueyang Zhang, et al.|  Baidu.inc and Peking University | <details><summary><small>This paper presents **GenCRF** ...</small></summary><small>The work proposes **GenCRF**, a Generative Clustering and Reformulation Framework to capture
diverse intentions adaptively based on multiple differentiated, well-generated queries in the retrieval phase. 1) It leverages LLMs to generate multiple differentiated queries by utilizing various types of custoomized prompts. 2) It clusters these queries and introduces similarity-based and score-based dynamic weighting, to adjust the relative weights of reformulated queries.</small></details> | <sub>BEIR</sub> |
| 2024/08/24 | [Meta Knowledge for Retrieval Augmented Large Language Models](https://arxiv.org/abs/2408.09017) | Laurent Mombaerts, Terry Ding, Florian Felice, Jonathan Taws, Adi Banerjee, Tarik Borogovac |  Amazon Web Services | <details><summary><small>This paper presents MK Summary ...</small></summary><small>The work proposes a novel data-centric RAG workflow for LLMs, relying on generating metadata and synthetic Questions and Answers (QA) for each document, as well as introducing the new concept of Meta Knowledge Summary (MK Summary) for metadata-based clusters of documents. It transforms the traditional retrieve-then-read system into a more advanced prepare-then-rewrite-then-retrieve-then-read framework, to achieve higher domain expert-level understanding of the knowledge base.</small></details> | <sub>arXiv</sub> |
| 2023/10/19 | [Large Language Models Know Your Contextual Search Intent: A Prompting Framework for Conversational Search](https://arxiv.org/abs/2303.06573) <br>[[code](https://github.com/kyriemao/LLM4CS): ![](https://img.shields.io/github/stars/kyriemao/LLM4CS.svg?style=social)] | Kelong Mao, Zhicheng Dou, Fengran Mo, Jiewen Hou, Haonan Chen, Hongjin Qian    | Renmin University of China | <details><summary><small>This paper presents LLM4CS ...</small></summary><small>The work proposes a simple yet effective prompting framework, called **LLM4CS**, to leverage LLMs as a text-based search intent interpreter to help conversational search.It explores three prompting methods to generate multiple query rewrites and hypothetical responses, and then proposes to aggregate them into an integrated representation.</small></details> | <sub>CAsT-19&20&21</sub> |
| 2023/10/11 | [Query2doc: Query Expansion with Large Language Models](https://arxiv.org/abs/2303.07678), <br>[[code](https://github.com/PKUnlp-icler/PCA-EVAL): ![](https://img.shields.io/github/stars/PKUnlp-icler/PCA-EVAL.svg?style=social)]  | Liang Wang, Nan Yang, Furu Wei                                                 | Microsoft Research | <details><summary><small>This paper presents Query2doc ...</small></summary><small>This work proposes a simple yet effective query expansion approach, denoted as **Query2doc**, to improve both sparse and dense retrieval systems. The proposed method first generates pseudo-documents by few-shot prompting large language models (LLMs), and then expands the query with generated pseudo-documents.</small></details>  | <sub>MS-MARCO passage, TREC-DL 19&20</sub> |
| 2023/6/16  | [GRM: Generative Relevance Modeling Using Relevance-Aware Sample Estimation for Document Retrieval](https://arxiv.org/abs/2306.09938)                                                                                                                                      | Iain Mackie, Ivan Sekulic, Shubham Chatterjee, Jeffrey Dalton, Fabio Crestani. | University of Glasgow,Università della Svizzera italiana  | <details><summary><small>This paper presents GRM ...</small></summary><small>This work proposes Generative Relevance Modeling **(GRM)** that uses Relevance-Aware Sample Estimation (RASE) for more accurate weighting of expansion terms. Specifically, it identifies similar real documents for each generated document and uses a neural re-ranker to estimate their relevance.</small></details>    | <sub>CODEC, Robust04</sub> |
|2022/12/20| [Precise Zero-Shot Dense Retrieval without Relevance Labels](https://arxiv.org/abs/2212.10496),<br> [[code](https://github.com/texttron/hyde): ![](https://img.shields.io/github/stars/texttron/hyde.svg?style=social)|Luyu Gao, Xueguang Ma, Jimmy Lin, Jamie Callan.|Language Technologies Institute, Carnegie Mellon University,David R. Cheriton School of Computer Science, University of Waterloo|<details><summary><small>This paper presents HyDE ...</small></summary><small>This work proposes to pivot through Hypothetical Document Embeddings(HyDE), which first zero-shot instructs an instruction-following language model to generate a hypothetical document and then grounds the generated document to the actual corpus with an unsupervised contrastively learned encoder.</small></details>| <sub>TREC-DL 19&20, BEIR</sub> |

### 3.2 Pseudo-Relevant Feedback <a id="PRF"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset   |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2023/8/2| [Large Language Models are Strong Zero-Shot Retriever](https://arxiv.org/abs/2304.14233)|Tao Shen, Guodong Long, Xiubo Geng, Chongyang Tao, Tianyi Zhou, Daxin Jiang|AAII, Microsoft,University of Maryland| <details><summary><small>This paper presents LameR ...</small></summary><small>This work proposes the Language language model as Retriever **(LameR)** to augment a query with its potential answers by prompting LLMs with a composition of the query and the query’s in-domain candidates and proposes to leverage a non-parametric lexicon-based method (e.g., BM25) as the retrieval module to capture query-document overlap in a literal fashion.</small></details>| <sub>MS-MARCO passage, TREC-DL 19&20, BEIR</sub> |

### 3.3 Methods Combination <a id="methods_combination"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset   | 
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2023/12/12| [Synergistic Interplay between Search and Large Language Models for Information Retrieval](https://arxiv.org/abs/2305.07402)<br>[[code](https://github.com/Cyril-JZ/InteR): ![](https://img.shields.io/github/stars/Cyril-JZ/InteR.svg?style=social)]|Tao Shen, Guodong Long, Xiubo Geng, Chongyang Tao, Tianyi Zhou, Daxin Jiang|Peking University, Microsoft,AAII| <details><summary><small>This paper presents InteR ...</small></summary><small>This work proposes **InteR**, a novel framework that facilitates information refinement through synergy between RMs and LLMs,which allows RMs to expand knowledge in queries using LLM-generated knowledge collections and enables LLMs to enhance prompt formulation using retrieved documents.</small></details>| <sub>TREC-DL 19&20, BEIR</sub> |
|2023/5/12| [Generative and Pseudo-Relevant Feedback for Sparse, Dense and Learned Sparse Retrieval](https://arxiv.org/abs/2305.07477)|Iain Mackie, Shubham Chatterjee, Jeffrey Dalton.|University of Glasgow| <details><summary><small>This paper presents ...</small></summary><small>This work proposes combining generative and pseudo-relevance feedback ranking signals to achieve the benefits of both feedback classes.</small></details>| <sub>Robust04, TREC-DL 19&20, CODEC</sub> |
|2023/5/5| [Query Expansion by Prompting Large Language Models](https://arxiv.org/abs/2305.03653)|LRolf Jagerman, Honglei Zhuang, Zhen Qin, Xuanhui Wang, Michael Bendersky.|Google Research| <details><summary><small>This paper presents ...</small></summary><small>This work proposes an approach to query expansion that leverages the generative abilities of Large Language Models (LLMs) and studies a variety of different prompts, including zero-shot, few-shot and Chain-of-Thought (CoT) finding that CoT prompts are especially useful for query expansion.</small></details>| <sub>MS-MARCO passage, BEIR</sub> |
