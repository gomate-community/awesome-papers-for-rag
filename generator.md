
## Introduction

Coming soon ...

## 1. Instruction Fine-tuning <a id="ift"></a>

### 1.1 Knowledge Enhance <a id="otm"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/03/15 <br> (ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ)| [RAFT: Adapting Language Model to Domain Specific RAG](https://arxiv.org/abs/2403.10131) [[code](https://github.com/ShishirPatil/gorilla): ![](https://img.shields.io/github/stars/ShishirPatil/gorilla.svg?style=social)]| Tianjun Zhang, Shishir G. Patil, Naman Jain, Sheng Shen, et al.|UC Berkeley|<details><summary><small>This paper presents *RAFT* ...</small></summary><small> RAFT leverages fine-tuning with question-answer pairs while referencing the documents in a simulated imperfect retrieval setting â€” thereby effectively preparing for the open-book exam setting. The RAFT is trained to answer the question (Q) from Document(s) (D) to generate answer (A), where A includes chain-of-thought reasoning.</small></details>| <sub>PubMed, HotpotQA, Gorilla</sub> |
|2023/5/18 <br> (ğŸŒŸğŸŒŸ)| [Augmented Large Language Models with Parametric Knowledge Guiding](https://arxiv.org/abs/2305.04757) | Ziyang Luo, Can Xu, Pu Zhao, et. al.,| Hong Kong Baptist University, Microsoft| <details><summary><small>This paper presents PKG ...</small></summary><small>This work propose Parametric Knowledge Guiding (**PKG**), which injects domain knowledge for LLaMa-7B via instruction fine-tuning to capture the necessary expertise. Then, the PKG is used to generage context for a given question as the background-augmented prompting for LLMs.</small></details>| <sub>FM2, NQ-Table, MedMC-QA, ScienceQA</sub>|


### 1.2 Attribution Enhance <a id="attribution"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2025/02/13 <br> (ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ) | [SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models](https://arxiv.org/pdf/2502.09604) | Yung-Sung Chuang, Benjamin Cohen-Wang, Shannon Zejiang Shen, Zhaofeng Wu, Hu Xu, Xi Victoria Lin, James Glass, Shang-Wen Li, Wen-tau Yih | Meta FAIR, MIT | <details><summary><small>This paper presents **SelfCite** ...</small></summary><small>SelfCite leverages a reward signal provided by the LLM itself through context ablation: If a citation is necessary, removing the cited text from the context should prevent the same response; if sufficient, retaining the cited text alone should preserve the same response. This reward can guide the inference-time best-of-N sampling strategy to improve citation quality significantly, as well as be used in preference optimization to directly fine-tune the models for generating better citations. </small></details>|<sub>LongBench-Cite</sub>|
|2024/12/19 <br> (ğŸŒŸğŸŒŸğŸŒŸ) | [VISA: Retrieval Augmented Generation with Visual Source Attribution](https://arxiv.org/pdf/2412.14457) | Xueguang Ma, Shengyao Zhuang, Bevan Koopman, Guido Zuccon, Wenhu Chen, Jimmy Lin | University of Waterloo, CSIR, University of Queensland | <details><summary><small>This paper presents **VISA** ...</small></summary><small>This work proposes Retrieval-Augmented Generation with Visual Source Attribution (VISA), which processes single or multiple retrieved document images, and generates an answer as well as the bounding box of the relevant region within the evidence document. They curated two datasets: Wiki-VISA and Paper-VISA, to fine-tune the QWen2-VL-72B</small></details>|<sub>Wiki-VISA, Paper-VISA</sub>|
|2024/09/10 <br> (ğŸŒŸğŸŒŸğŸŒŸ) | [LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA](https://arxiv.org/abs/2409.02897) [[code](https://github.com/THUDM/LongCite): ![](https://img.shields.io/github/stars/THUDM/LongCite.svg?style=social)] | Jiajie Zhang, Yushi Bai, Xin Lv, et. al.| Tsinghua University| <details><summary><small>This paper presents **LongCite** ...</small></summary><small>This work proposes CoF (abbr. for â€œCoarse to Fineâ€), that utilizes off-the-shelf LLMs to automatically construct long-context QA instances with precise sentence-level citations. CoF comprises four stages: (1) Starting with a long text material, CoF first invokes the LLM to produce a query and its answer through Self-Instruct. (2) CoF uses the answer to retrieve several chunks from the context, which are then fed into the LLM to incorporate coarse-grained chunk-level citations within the answer. (3) The LLM identifies relevant sentences from each cited chunk to produce fine-grained citations. (4) instances with an insufficient number of citations are discarded. </small></details>|<sub>LongBench-Cite</sub>|
|2024/08/20 <br> (ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ) | [INSTRUCTRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales](https://arxiv.org/pdf/2406.13629) [[code](https://github.com/weizhepei/InstructRAG): ![](https://img.shields.io/github/stars/weizhepei/InstructRAG.svg?style=social)] | Zhepei Wei, Wei-Lin Chen, Yu Meng | University of Virginia | <details><summary><small>This paper presents **InstructRAG** ...</small></summary><small>This work proposes InstructRAG to generate rationales along with the answer, enhancing both the generation accuracy and trustworthiness. It first prompt an instruction-tuned LLM (rational generator) to synthesize rationales, which is to explain how to derive correct answer from noisy retrieved documents. Then, it guid the LM to learn explict denoising by leveraging these rationals as either in-context learning demonstrations or as supervised fine-tuning data.</small></details>|<sub>PopQA, TriviaQA, NQ, ASQA, 2WikiMHQA </sub>|
|2024/08/08 <br> (ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ) | [Learning Fine-Grained Grounded Citations for Attributed Large Language Models](https://arxiv.org/abs/2408.04568) [[code](https://github.com/LuckyyySTA/Fine-grained-Attribution): ![](https://img.shields.io/github/stars/LuckyyySTA/Fine-grained-Attribution.svg?style=social)] | Lei Huang, Xiaocheng Feng, Weitao Ma, et. al. | Harbin Institute of Technology, Harbin | <details><summary><small>This paper presents **FRONT** ...</small></summary><small>This work introduces *FRONT*, a two-stage training framework designed to teach LLMs to generate Fine-gRained grOuNded ciTations, consisting of Grounding Guided Generation (G3) and Consistency-Aware Alignment (CAA). During the G3 stage, the LLM first selects supporting quotes from retrieved sources (grounding) and then conditions the generation process on them (generation). The CAA stage then utilizes preference optimization to further align the grounding and generation process by automatically constructing preference signals. </small></details>|<sub>ALCE(ASQA, ELI5, QAMPARI)</sub>|
|2024/07/01 <br> (ğŸŒŸğŸŒŸğŸŒŸ)  | [Ground Every Sentence: Improving Retrieval-Augmented LLMs with Interleaved Reference-Claim Generation](https://arxiv.org/pdf/2407.01796) | Sirui Xia, Xintao Wang, Jiaqing Liang, et al. | Fudan University, AntGroup | <details><summary><small>This paper presents **ReClaim** ...</small></summary><small>Contributions: 1) ReClaim alternately generates citations and answer sentences, to enable large models to generate answer with citations. 2) For ReClaim, they constructed a training dataset and fine-tuned the model using different approaches to improve its attribution capability. 3) Through multiple experiments, they demonstrated the effectiveness of the method in enhancing the modelâ€™s verifiability and credibility. </small></details>|<sub>ASQA, ELI5 </sub>|
|2024/03/27<br> (ğŸŒŸ)  | [Improving Attributed Text Generation of Large Language Models via Preference Learning](https://arxiv.org/pdf/2403.18381) [[code](https://github.com/HITsz-TMG/ATG-PO): ![](https://img.shields.io/github/stars/HITsz-TMG/ATG-PO.svg?style=social)] | Dongfang Li, Zetian Sun, Baotian Hu, et. al. | Harbin Institute of Technology (Shenzhen) | <details><summary><small>This paper presents APO ...</small></summary><small>This work conceptualize the attribution task for LLMs as preference learning and proposing an Automatic Preference Optimization (APO) framework. They assemble a curated dataset comprising 6,330 examples sourced and refined from existing datasets for posttraining. Beside, they further propose an automatic method to synthesize attribution preference data resulting in 95,263 pairs. </small></details>|<sub>ASQA, StrategyQA, ELI5</sub>|
|2024/03/04 <br> (ğŸŒŸğŸŒŸ)  | [Citation-Enhanced Generation for LLM-based Chatbots](https://arxiv.org/pdf/2402.16063) | Weitao Li, Junkai Li, Weizhi Ma, Yang Liu | Tsinghua University | <details><summary><small>This paper presents CEG ...</small></summary><small>This work proposes a post-hoc Citation-Enhanced Generation (CEG) approach combined with RAG. It consists of three components: 1) *Retrieval Augmentation Module* uses NLTK as sentence tokenizer to obtain claims, then uses dense retrieval (SimCSE Bert) to retrieve documents; 2) *Citation Generation Module* first uses NLI model to determine the relationship between each claim-document pair to select valid reference for each claim; 3) *Response Regeneration Module* takes the question, original response, nonfactual claims, and relevant docs, as prompt input to regenerate the new response.</small></details>|<sub>WikiBio GPT-3, FELM, HaluEval, WikiRetr </sub>|

### 1.3 Long-context Enhance <a id="attribution"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2025/06/04 <br> (ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ)  | [Stronger Baselines for Retrieval-Augmented Generation with Long-Context Language Models](https://arxiv.org/pdf/2506.03989) [[code](https://github.com/alex-laitenberger/stronger-baselines-rag/): ![](https://img.shields.io/github/stars/alex-laitenberger/stronger-baselines-rag.svg?style=social)] | Alex Laitenberger, Christopher D. Manning, Nelson F. Liu |  Stanford University | <details><summary><small>This paper compares **DOS RAG** ...</small></summary><small>This paper aims to study ``With long-context LLMs (GPT-4o), do multistage retrieval-augmented generation (RAG) pipelines still offer measurable benefits over simpler, single-stage approaches''. The results show that DOS RAG consistently matches or outperforms more intricate methods on âˆBench, QuALITY, NarrativeQA. </small></details>|<sub>âˆBench, QuALITY, NarrativeQA</sub>|
|2024/09/01 <br> (ğŸŒŸğŸŒŸğŸŒŸ)  | [LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs](https://arxiv.org/pdf/2406.15319) [[code](https://github.com/TIGER-AI-Lab/LongRAG/): ![](https://img.shields.io/github/stars/TIGER-AI-Lab/LongRAG.svg?style=social)] | Ziyan Jiang, Xueguang Ma, Wenhu Chen |  University of Waterloo | <details><summary><small>This paper presents **LongRAG** ...</small></summary><small>The LongRAG consists of a "long retriever" and a "long reader", which processes the entire Wikipedia into 4K-token units, which is 30x longer than before. It adopts off-the-shelf BGE as retriever and Gemini1.5-Pro or GPT-4o as readers without any further tuning. </small></details>|<sub>NQ, HotpotQA, Qasper, MultiFieldQA-en </sub>|
|2024/07/11 <br> (ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ)  | [LLM Maybe LongLM: SelfExtend LLM Context Window Without Tuning](https://arxiv.org/pdf/2401.01325) [[code](https://github.com/datamllab/LongLM): ![](https://img.shields.io/github/stars/datamllab/LongLM.svg?style=social)] | ZHongye Jin, Xiaotian Han, Jingfeng Yang, et. al. | Texas A&M University | <details><summary><small>This paper presents SelfExtend ...</small></summary><small>SelfExtend extend the context window of LLMs by construncting bi-level attention information without fine-tuning: 1) The grouped attention captures the dependencies amongo tokens that are far apart; 2) The neighbor attention captures dependencies among adjacent tokens within a specified range</small></details>|<sub>LongBench, L-Eval </sub>|
|2024/05/29 <br> (ğŸŒŸğŸŒŸğŸŒŸ) | [Beyond the Limits: A Survey of Techniques to Extend the Context Length in Large Language Models](https://arxiv.org/pdf/2402.02244) | Xindi Wang, Mahsa Salmani, Parsa Omidi, et. al. | Huawei Tech. Canada, University of Western Ontario | <details><summary><small>This paper presents a survey ...</small></summary><small>This paper survey works in enabling LLMs to handle long sequences, including *length extrapolation*, *attention approximation*, *attention-free transformers*, *model compression*, and *hardware-aware transformers*.</small></details>|<sub>None</sub>|

### 1.4 Reasoning Enhance <a id="reason"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/09/01 <br> (ğŸŒŸğŸŒŸ)  | [ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates](https://arxiv.org/abs/2502.06772) [[code](https://github.com/Gen-Verse/ReasonFlux/): ![](https://img.shields.io/github/stars/Gen-Verse/ReasonFlux.svg?style=social)] | Ling Yang, Zhaochen Yu, Bin Cui, Mengdi Wang | Princeton University, Peking University | <details><summary><small>**ReasonFlux**: Finetuning, Qwen2.5.</small></summary><small>It train the *ReasonFlux-32B* model with 8 GPUs and introduces three innovations: (i) a structured **thought template library**, containing around 500 high-level thought templates; (ii) performing hierarchical reinforcement learning on a sequence of thought templates, optimizing a base LLM to plan out an optimal template trajectory for gradually handling complex problems; (iii) a brand new inference scaling system that enables hierarchical LLM reasoning by adaptively scaling thought templates at inference time. </small></details>|<sub> MATH, AIME 2024, AMC 2023, OlympiadBench, Gaokao, En 2023 </sub>|

## 2. Haullucinations <a id="hallucinations"></a><br>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2023/09/13 <br> (ğŸŒŸğŸŒŸ)  | [Cognitive Mirage: A Review of Hallucinations in Large Language Models](https://arxiv.org/pdf/2309.06794.pdf) | Hongbin Ye, Tong Liu, Aijia Zhang, Wei Hua, Weiqiang Jia | Zhejiang Lab | <details><summary><small>This paper presents taxonomy of hallucinations ...</small></summary><small>This work provides a literature review on hallucinations, which presents a taxonomy of hallucinations from several text generation tasks, and mechanism analysis (three types: data collection, knowledge gap, and optimization process), detection methods and improvement approaches.</small></details>| <sub>-</sub>|

## 3. Understanding of LLM <a id="understand"></a><br>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2025/05/26 <br> (ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ)  | [SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training](https://arxiv.org/pdf/2501.17161) | Tianzhe Chu, Yuexiang Zhai, Jihan Yang, et al. | HKU | <details><summary><small>This paper studies the comparative effect of **SFT** and **RL** on generalization and memorization ... </small></summary><details><small> This paper introduces **GeneralPoints**, an arithmetic reasoning card game, and also consider **V-IRL**, a real-world navigation environment, to assess how models trained with SFT and RL generalize to unseen variants. Findings: 1) RL, especially trained with an outcome-based reward, generalizes in both rule-based textual and visual environments. 2) SFT, tends to memorize the training data and struggle to generalize out-of-distribution in either scenario.</small></details>| <sub>GeneralPoints, V-IRL</sub>|
|2025/05/02 <br> (ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ)  | [Physics of Language Models: Part 4.1, Architecture Design and the Magic of Canon Layers](http://zeyuan.allen-zhu.com/paper/2025-canon.pdf) | Zeyuan Allen-Zhu | Meta/FAIR Labs | <details><summary><small>This paper studies architectural differences in LMs... </small></summary><details><small> This paper introduces controlled synthetic pretraining tasks that isolate and evaluate core model capacities. They discover **Canon layers**: lightweight architectural components, that promote horizontal infromation flow across neighboring tokens. </small></details>| <sub>controlled biography dataset</sub>|
|2024/04/08 <br> (ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ)  | [Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws](https://arxiv.org/pdf/2404.05405) | Zeyuan Allen-Zhu, Yuanzhi Li | Meta/FAIR Labs | <details><summary><small>This paper studies knowledge capacity scaling laws... </small></summary><details><small> This paper investigate the number of knowldge *bits* a mall stores. They focus on factual knowledge represented as tuples. Findings: 1) LMs can only store *2 bits of knowledge per parameter, even when quantized to int8*, and 7B model can store 14B bits of knowledge. 2) The GPT-2 architecture, with rotary embedding, matches or even surpasses LLaMA/Mistral architectures in knowledge storage, particularly over shorter training durations. 3)Prepending training data with domain names (e.g., wikipedia.org) significantly increases a modelâ€™s knowledge capacity. </small></details>| <sub>controlled biography dataset</sub>|
|2023/09/18 <br> (ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ)  | [Physics of Language Models: Part 3.2, Knowledge Manipulation](https://arxiv.org/pdf/2309.14402) | Zeyuan Allen-Zhu, Yuanzhi Li | Meta/FAIR Labs | <details><summary><small>This paper studies knowledge manipulation of LLMs... </small></summary><details><small> This paper investigate four knowledge manipulation tasks: retrieval, classification, comparison, and inverse search. Findings: 1) LLM **excel in knowledge retrieval** but **struggle even in the simplest classification or comparison tasks unless Chain of Thoughts (CoT)**, and 2) the performance of **inverse knowledge search is virtually 0%**, regardless of the prompts.</small></details>| <sub>controlled biography dataset</sub>|
|2023/09/18 <br> (ğŸŒŸğŸŒŸğŸŒŸğŸŒŸ)  | [Physics of Language Models: Part 3.1, Knowledge Storage and Extraction](https://arxiv.org/pdf/2309.14316) | Zeyuan Allen-Zhu, Yuanzhi Li | Meta/FAIR Labs | <details><summary><small>This paper studies knowledge storage and Extraction of LLMs... </small></summary><details><small> This paper investigate whether the question-answering capabilities of LLMs stem from **pattern recognition and memorization** or from **a genuine ability to reason and extract knowledge** from their training data. Findings: 1) rewrite the pre-training data-using small, auxiliary models-to provide knowledge augmentation, and 2) incorporate more instruction-finetuning data into the pretraining stage before it becomes too late.</small></details>| <sub>controlled biography dataset</sub>|

## 4. Datasets <a id="datasets"></a>

### 4.1 Factoid QA <a id="fqa"></a>

| Date       | Title | Authors   | Orgnization | Abs    | Dataset                                                                                           |
|------------|-----------------------------------------------------------------------------------------------------------------|------------------------------------------|---------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
|2024/01/26 | [Benchmarking Large Language Models in Complex Question Answering Attribution using Knowledge Graphs](https://arxiv.org/abs/2401.14640.pdf)| Nan Hu, Jiaoyan Chen, Yike Wu, Guilin Qi, Sheng Bi, Tongtong Wu, Jeff Z. Pan.|Southeast University, The University of Manchester,The University of Edinburgh |<details><summary><small>This paper presents CAQA ...</small></summary><small>CAQA is a new benchmark for complex question answering attribution, which is designed to evaluate the ability of LLMs to answer complex questions with the help of knowledge graphs.</small></details>| <sub> CAQA </sub>|
|2022/04/12| [ASQA: Factoid Questions Meet Long-Form Answers](https://arxiv.org/abs/2204.06092.pdf) [[dataset](https://huggingface.co/datasets/din0s/asqa)]|Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, Ming-Wei Chang|Carnegie Mellon University, Duke University, Google Research |<details><summary><small>This paper presents ASQA ...</small></summary><small>ASQA is the first long-form question answering dataset that focuses on ambiguous factoid questions.</small></details>| <sub>ASQA</sub>|

### 3.2 Long-form QA <a id="lfqa"></a>

